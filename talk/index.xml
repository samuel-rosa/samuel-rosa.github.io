<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Recent &amp; Upcoming Talks on A. Samuel-Rosa</title>
    <link>http://samuel-rosa.github.io/talk/</link>
    <description>Recent content in Recent &amp; Upcoming Talks on A. Samuel-Rosa</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>pt-br</language>
    <lastBuildDate>Sun, 01 Jan 2017 00:00:00 +0000</lastBuildDate>
    <atom:link href="/talk/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Stacked generalization of statistical learners -- a case study with soil iron content in Brazil</title>
      <link>http://samuel-rosa.github.io/talk/pedometrics-2017/</link>
      <pubDate>Thu, 29 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>http://samuel-rosa.github.io/talk/pedometrics-2017/</guid>
      <description>&lt;div id=&#34;resumo&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Resumo&lt;/h2&gt;
&lt;p&gt;When modeling soil-landscape relationships we generally test a handful of statistical learners. Having limited data, we use cross-validation to select the best performing learner. In this study we evaluate the benefits of combining learners for soil prediction using stacked generalization. It consists of calibrating multiple learners and submitting them to 10-fold cross-validation. Cross-validation predictions are used as covariates in an interceptless linear regression of the target variable. Constrained to be non-negative, the estimated regression coefficients are the stacking weights expressing the importance of each learner. When making predictions, each learner is used in turn and the weights used to optimally combine multiple predictions into a single prediction.&lt;/p&gt;
&lt;p&gt;The data was downloaded from the national database maintained by Embrapa. The target variable was the soil iron content (g kg&lt;sup&gt;-1&lt;/sup&gt;). Covariates (&lt;em&gt;p&lt;/em&gt; = 7) were constructed using soil profile data. The &lt;em&gt;n&lt;/em&gt; = 22 981 records remaining after some data cleaning were split into calibration (&lt;em&gt;n&lt;/em&gt;&lt;sub&gt;cal&lt;/sub&gt; = 16 086) and validation (&lt;em&gt;n&lt;/em&gt;&lt;sub&gt;val&lt;/sub&gt; = 6895) sets. Six learners were used: linear regression with stepwise selection (&lt;code&gt;lm&lt;/code&gt;), multivariate adaptive regression splines (&lt;code&gt;mars&lt;/code&gt;), regression random forest (&lt;code&gt;rf&lt;/code&gt;), single-hidden-layer neural network (&lt;code&gt;nnet&lt;/code&gt;), weighted k-nearest neighbor regression (&lt;code&gt;knn&lt;/code&gt;) and support vector machine with polynomial kernel (&lt;code&gt;svm&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;&lt;code&gt;rf&lt;/code&gt; and &lt;code&gt;knn&lt;/code&gt; severely overfitted the data, while &lt;code&gt;lm&lt;/code&gt;, &lt;code&gt;mars&lt;/code&gt; and &lt;code&gt;svm&lt;/code&gt; were the most stable learners. The first two yielded the lowest absolute and squared errors (RMSE &amp;lt; 45 g kg&lt;sup&gt;-1&lt;/sup&gt;) and explained more of the variance (AVE ~ 0.6). &lt;code&gt;mars&lt;/code&gt;, &lt;code&gt;nnet&lt;/code&gt; and &lt;code&gt;lm&lt;/code&gt; were the least biased learners (ME ~ -0.1 g kg&lt;sup&gt;-1&lt;/sup&gt;), while &lt;code&gt;svm&lt;/code&gt; was the most biased (ME = -5.14 g kg&lt;sup&gt;-1&lt;/sup&gt;). &lt;code&gt;lm&lt;/code&gt; explained the smallest amount of variance (AVE = 0.49).&lt;/p&gt;
&lt;p&gt;&lt;code&gt;rf&lt;/code&gt; received the largest stacking weight (&lt;em&gt;w&lt;/em&gt; = 0.55), &lt;code&gt;knn&lt;/code&gt; and &lt;code&gt;svm&lt;/code&gt; received moderate weights (&lt;em&gt;w&lt;/em&gt; ~ 0.2) and &lt;code&gt;nnet&lt;/code&gt; and &lt;code&gt;mars&lt;/code&gt; received the smallest weights (&lt;em&gt;w&lt;/em&gt; &amp;lt; 0.1) – &lt;code&gt;lm&lt;/code&gt; was dropped from the stack (&lt;em&gt;w&lt;/em&gt; = 0). Combining learners lowered all absolute and squared errors (RMSE = 43.23 g kg&lt;sup&gt;-1&lt;/sup&gt;), yielded a considerably small bias (ME = 0.53 g kg&lt;sup&gt;-1&lt;/sup&gt;), and explained the same amount of variance explained by &lt;code&gt;rf&lt;/code&gt; (AVE = 0.61).&lt;/p&gt;
&lt;p&gt;Staking learners was more beneficial than using the single best performing learner because it reduced generalization errors. The magnitude of the benefits seems to depend upon the diversity of learners (over and underfitting, biased and nonbiased). Besides, by using least squares regression to compute stacking weights we can estimate the prediction error variance of any combination of learners.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;informacoes-adicionais&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Informações adicionais&lt;/h2&gt;
&lt;p&gt;Este trabalho foi realizado em parceria com &lt;a href=&#34;http://lattes.cnpq.br/3735884911693854&#34;&gt;Ricardo Dalmolin&lt;/a&gt;, pesquisador do Programa de Pós-Graduação em Ciência do Solo (&lt;a href=&#34;http://w3.ufsm.br/ppgcs/index.php&#34;&gt;PPGCS&lt;/a&gt;) da Universidade Federal de Santa Maria (&lt;a href=&#34;http://site.ufsm.br/&#34;&gt;UFSM&lt;/a&gt;). O desenvolvimento do trabalho e sua apresentação no Pedometrics 2017 foram viabilizados pelo PPGCS via Programa Nacional de Pós Doutorado (&lt;a href=&#34;http://www.capes.gov.br/bolsas/bolsas-no-pais/pnpd-capes&#34;&gt;PNPD&lt;/a&gt;) da CAPES, e com recursos dos projetos de pesquisa desenvolvidos por Ricardo Dalmolin no PPGCS.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Building a Public Repository of Open Soil Iron Data for Brazil</title>
      <link>http://samuel-rosa.github.io/talk/bspm-2017/</link>
      <pubDate>Mon, 29 May 2017 00:00:00 +0000</pubDate>
      
      <guid>http://samuel-rosa.github.io/talk/bspm-2017/</guid>
      <description>&lt;div id=&#34;resumo&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Resumo&lt;/h2&gt;
&lt;p&gt;We have recently stimulated the emergence of an unprecedented collaborative effort among soil scientists from all over Brazil. The goal: to build a centralized, public and free repository of standardized and georeferenced soil iron data with national coverage. Many Brazilian soil scientists have already shared datasets, some of them even before we could insert the datasets in possession of our institutions in what we called the Brazilian Soil Iron Data Repository (&lt;a href=&#34;http://coral.ufsm.br/febr/&#34;&gt;Fe-BR&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Since December 2016, Fe-BR already has some 26 thousand records from about 300 datasets, most of them from the Brazilian Soil Information System (&lt;a href=&#34;https://www.bdsolos.cnptia.embrapa.br/consulta_publica.html&#34;&gt;SISB&lt;/a&gt;) maintained by Embrapa. Along this period, we have seen that soil scientists are eager to share the datasets in their possession but are very sensitive to the extra efforts needed to do so. As such, we have designed a system that relies on data manipulation tools that are well known to all – spreadsheets. We also aimed at a suite of tools that meets the basic technological requirements of a robust but flexible data repository – version control, persistent identification, multiple file export options, concurrent edition, reviewing tools. The free online service Google Sheets has been able to fulfil all of these requirements. With Google Sheets, datasets in Fe-BR can be reviewed and/or augmented at any time by anyone on the internet with the permission to do so. This participatory approach can potentially boost the development of a completely new type of community driven, free and open soil data repository.&lt;/p&gt;
&lt;p&gt;There has obviously been some difficulties, such as (1) motivating authors to provide comprehensive metadata and adhere to standards, (2) guessing spatial coordinates of non-georeferenced soil observations, (3) establishing communication between data sources, and (4) finding people willing to help in data organization and standardization. Solutions for (3) usually increase the need for more collaborators thus inflating (4). Solving (1) seems to depend upon consistent and persistent awareness raising. Fortunately the enthusiasm and sense of public responsibility of soil scientists, and availability of free online collaborative mapping services such as Google Maps, have made it easier to solve (2).&lt;/p&gt;
&lt;p&gt;Next steps include launching a metadata catalog with search tools and improving the &lt;a href=&#34;https://github.com/samuel-rosa/febr-package&#34;&gt;febr&lt;/a&gt; package for R. Soil scientists are encouraged to use Fe-BR data to improve taxonomic systems, evaluate analytical methods, produce soil maps, identify priority areas for sampling and so on.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;informacoes-adicionais&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Informações adicionais&lt;/h2&gt;
&lt;p&gt;Este trabalho foi realizado em parceria com &lt;a href=&#34;http://lattes.cnpq.br/3735884911693854&#34;&gt;Ricardo Dalmolin&lt;/a&gt;, pesquisador do Programa de Pós-Graduação em Ciência do Solo (&lt;a href=&#34;http://w3.ufsm.br/ppgcs/index.php&#34;&gt;PPGCS&lt;/a&gt;) da Universidade Federal de Santa Maria (&lt;a href=&#34;http://site.ufsm.br/&#34;&gt;UFSM&lt;/a&gt;). Participaram, também, &lt;a href=&#34;http://lattes.cnpq.br/7251203817503318&#34;&gt;Paulo Gubiani&lt;/a&gt; (PPGCS/UFSM), [Stanley Oliveira][stanley] (Embrapa), &lt;a href=&#34;http://lattes.cnpq.br/5351112741475859&#34;&gt;Humberto dos Santos&lt;/a&gt; (Embrapa) e &lt;a href=&#34;http://www.isric.org/user/34&#34;&gt;Eloi Ribeiro&lt;/a&gt; (ISRIC). O desenvolvimento do trabalho e sua apresentação no BSPM 2017 foram viabilizados pelo PPGCS via Programa Nacional de Pós Doutorado (&lt;a href=&#34;http://www.capes.gov.br/bolsas/bolsas-no-pais/pnpd-capes&#34;&gt;PNPD&lt;/a&gt;).&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
